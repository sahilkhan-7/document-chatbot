# ğŸ“š Chat with Multiple Documents using RAG ğŸš€  

This project is a **Streamlit-based web application** that allows users to upload multiple documents (PDF, DOCX, TXT) and interact with them using a chatbot interface. The chatbot is powered by the **Groq API** and leverages **LangChain** for conversational retrieval, providing structured and concise answers from the uploaded documents.

---

## ğŸš€ **Project Overview**  
This project integrates **LangChain** and **Groq LLM** to enable users to:  
âœ… Upload and process multiple document types (PDF, DOCX, TXT)  
âœ… Extract and split document text into manageable chunks  
âœ… Store document embeddings using **FAISS** (Facebook AI Similarity Search)  
âœ… Retrieve and generate answers based on user queries  
âœ… Handle multi-turn conversations with memory retention  

---

## ğŸ† **Features**  
âœ”ï¸ Supports multiple file formats (PDF, DOCX, TXT)  
âœ”ï¸ Uses **FAISS** for fast and efficient document retrieval  
âœ”ï¸ Handles conversational context with **LangChain's memory module**  
âœ”ï¸ Provides structured responses using **Groq LLM**  
âœ”ï¸ Streamlit-based intuitive UI with file upload and clear chat options  

---

## ğŸ› ï¸ **Technologies Used**  
| Technology | Purpose |
|-----------|---------|
| **Streamlit** | For building the web-based user interface |
| **LangChain** | For conversational retrieval and memory handling |
| **Groq LLM** | For generating accurate and structured responses |
| **FAISS** | For fast document retrieval using embeddings |
| **HuggingFace Embeddings** | For generating vector embeddings of text chunks |
| **PyPDFLoader, Docx2txtLoader, TextLoader** | For reading and processing documents |

---

## ğŸŒ **Project Workflow**  

### 1. **Document Upload & Processing**  
- User uploads multiple files (PDF, DOCX, TXT).  
- Files are saved temporarily and processed using appropriate loaders.  
- Text content is extracted and converted into document objects.  

### 2. **Text Splitting & Vectorization**  
- Documents are split into smaller chunks using **RecursiveCharacterTextSplitter**.  
- Text chunks are embedded using **HuggingFace sentence-transformers**.  
- Embeddings are stored in a **FAISS vector store** for efficient retrieval.  

### 3. **Conversational Retrieval Chain**  
- User input is processed using **LangChain's ConversationBufferMemory**.  
- Context from previous turns is added to maintain conversational memory.  
- Groq LLM generates structured and concise responses.  

### 4. **Chat Display & Handling**  
- User input and AI-generated responses are displayed on the interface.  
- "Clear Chat" button resets the session history and memory.  

---

## ğŸ¯ **Impact**  
âœ… **Efficient Document-Based Q&A:** The system allows users to extract meaningful insights from large documents quickly.  
âœ… **Structured Answers:** Groq LLM ensures that answers are well-organized and concise, enhancing user experience.  
âœ… **Fast Retrieval:** FAISS enables fast and scalable search across large datasets.  
âœ… **User-Friendly Interface:** The Streamlit-based interface ensures ease of use for both technical and non-technical users.  

---

## ğŸ”® **Future Scope**  
ğŸš€ **Add Support for More File Formats:** Expand support to CSV, JSON, and other document types.  
ğŸš€ **Advanced Search:** Enable keyword-based search with semantic matching.  
ğŸš€ **Improved Context Handling:** Enhance memory capabilities for long-term conversation handling.  
ğŸš€ **Multi-Model Support:** Allow integration of other LLMs (OpenAI, Claude, DeepSeek) for more diversified responses.  
ğŸš€ **Enhanced UI:** Add options for formatting answers and downloading conversation history.  

---

## ğŸ† **Author**  
**Sahil Khan**  
- [LinkedIn](https://linkedin.com/in/sahilkhan7)  
- [GitHub](https://github.com/sahilkhan-7)  

---

## ğŸ **How to Run the Project**  

### **1. Clone the Repository**  
```bash
git clone https://github.com/sahilkhan-7/documents-chatbot.git
cd chat-with-documents
```

### **2. Install Dependencies**  
```bash
pip install -r requirements.txt
```

### **3. Create `.env` File**  
Add your Groq API Key in `.env` file:  
```
GROQ_API_KEY="your-groq-api-key"
```

### **4. Run the Application**  
```bash
streamlit run app.py
```